{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Агрегаты и оконные функции, сортировка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Агрегаты\n",
    "\n",
    "* агрегирование - это получение итогового значения по некой группе\n",
    "* \"тип\" итогового значения обычно определяется агрегирующей функцией (sum, max, ...)\n",
    "* группировать можно разными способами\n",
    "    * по всему датафрейму (нет группировки)\n",
    "    * по его колонкам датафрейма\n",
    "    * с использованием \"оконных\" функций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Агрегирующие функции\n",
    "\n",
    "Их много, см. документацию, основные - min(), max(), sum(), count(), countDistinct().\n",
    "\n",
    "Агрегирующие функции - это трансформации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Группировка\n",
    "\n",
    "* `df.select(sum(\"column\"))` - по всему датафрейма\n",
    "* `groupBy()` - создает `RelationalGroupedDataset`, который потом агрегируем\n",
    "* оконная функция задает `window`, которое потом используется агрегирующей функцией\n",
    "\n",
    "Оконные функции - мощный и универсальный механизм, см. материалы, там приведеные примеры его применения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сортировка\n",
    "\n",
    "* два метода (синонимы) `sort()` и `orderBy()`\n",
    "* сортируем по значению колонки/колонок\n",
    "* задавать колонки можно именами или строковым выражением\n",
    "* сортировать можно по возрастанию или убыванию\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Практикуемся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/mk/mk_win/projects/SparkEdu/lib/python3.5/site-packages/pyspark\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"python3\"\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"pyspark-shell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"spark_aggr\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = spark.read.format(\"csv\") \\\n",
    "    .option(\"mode\", \"FAILFAST\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .option(\"path\", \"data/countries of the world.csv\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Без группировки**\n",
    "\n",
    "Агрегируем по всему датафрейму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|max(Population)|\n",
      "+---------------+\n",
      "|     1313973713|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cdf.select(f.max(\"Population\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**groupBy**\n",
    "\n",
    "Посмотрим агрегат в разбивке по колонке (используем groupBy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|              Region|max(Population)|\n",
      "+--------------------+---------------+\n",
      "|BALTICS          ...|        3585906|\n",
      "|C.W. OF IND. STATES |      142893540|\n",
      "|ASIA (EX. NEAR EA...|     1313973713|\n",
      "|WESTERN EUROPE   ...|       82422299|\n",
      "|NORTHERN AMERICA ...|      298444215|\n",
      "|NEAR EAST        ...|       70413958|\n",
      "|EASTERN EUROPE   ...|       38536869|\n",
      "|OCEANIA          ...|       20264082|\n",
      "|SUB-SAHARAN AFRIC...|      131859731|\n",
      "|NORTHERN AFRICA  ...|       78887007|\n",
      "|LATIN AMER. & CAR...|      188078227|\n",
      "+--------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cdf.groupBy(\"Region\").max(\"Population\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**оконная функция**\n",
    "\n",
    "Сделаем то же самое, но с использованием оконной функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|              Region|MaxPopulation|\n",
      "+--------------------+-------------+\n",
      "|BALTICS          ...|      3585906|\n",
      "|C.W. OF IND. STATES |    142893540|\n",
      "|ASIA (EX. NEAR EA...|   1313973713|\n",
      "|WESTERN EUROPE   ...|     82422299|\n",
      "|NORTHERN AMERICA ...|    298444215|\n",
      "|NEAR EAST        ...|     70413958|\n",
      "|EASTERN EUROPE   ...|     38536869|\n",
      "|OCEANIA          ...|     20264082|\n",
      "|SUB-SAHARAN AFRIC...|    131859731|\n",
      "|NORTHERN AFRICA  ...|     78887007|\n",
      "|LATIN AMER. & CAR...|    188078227|\n",
      "+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "windowSpec = Window.partitionBy(\"Region\")\n",
    "cdf.select(\"Region\",f.max(\"Population\").over(windowSpec).alias(\"MaxPopulation\")).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сортировка**\n",
    "\n",
    "Упорядочим предыдущий результат по убыванию максимального населения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|              Region|MaxPopulation|\n",
      "+--------------------+-------------+\n",
      "|ASIA (EX. NEAR EA...|   1313973713|\n",
      "|NORTHERN AMERICA ...|    298444215|\n",
      "|LATIN AMER. & CAR...|    188078227|\n",
      "|C.W. OF IND. STATES |    142893540|\n",
      "|SUB-SAHARAN AFRIC...|    131859731|\n",
      "|WESTERN EUROPE   ...|     82422299|\n",
      "|NORTHERN AFRICA  ...|     78887007|\n",
      "|NEAR EAST        ...|     70413958|\n",
      "|EASTERN EUROPE   ...|     38536869|\n",
      "|OCEANIA          ...|     20264082|\n",
      "|BALTICS          ...|      3585906|\n",
      "+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cdf.select(\"Region\",f.max(\"Population\").over(windowSpec).alias(\"MaxPopulation\")).distinct().sort(f.desc(\"MaxPopulation\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Минимум или максимум**\n",
    "\n",
    "Завершающий пример - чуть усложним: найдем страны с минимальным и максимальным населением в регионах\n",
    "\n",
    "Комментарии:\n",
    "\n",
    "* оконная функция просто группирует по региону\n",
    "* добавляем колонки с минимальным и максимальным населением по региону (`minp, maxp`)\n",
    "* оставляем в датафрейме только страны, население которых самое маленькое или большое (используем expr)\n",
    "* добавляем колонку `which`, в которую записываем - какая это страна (с минимальным или максимальным населением, используем функции `when().otherwise()`\n",
    "* удалим неинтересные нам колонки (`select()`)\n",
    "* упорядочим - покажем сначала самые большие страны, потом - самые маленькие (по убыванию населения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+-----+\n",
      "|             Country|              Region|Population|which|\n",
      "+--------------------+--------------------+----------+-----+\n",
      "|              China |ASIA (EX. NEAR EA...|1313973713|  MAX|\n",
      "|      United States |NORTHERN AMERICA ...| 298444215|  MAX|\n",
      "|             Brazil |LATIN AMER. & CAR...| 188078227|  MAX|\n",
      "|             Russia |C.W. OF IND. STATES | 142893540|  MAX|\n",
      "|            Nigeria |SUB-SAHARAN AFRIC...| 131859731|  MAX|\n",
      "|            Germany |WESTERN EUROPE   ...|  82422299|  MAX|\n",
      "|              Egypt |NORTHERN AFRICA  ...|  78887007|  MAX|\n",
      "|             Turkey |NEAR EAST        ...|  70413958|  MAX|\n",
      "|             Poland |EASTERN EUROPE   ...|  38536869|  MAX|\n",
      "|          Australia |OCEANIA          ...|  20264082|  MAX|\n",
      "|          Lithuania |BALTICS          ...|   3585906|  MAX|\n",
      "|            Armenia |C.W. OF IND. STATES |   2976372|  MIN|\n",
      "|           Slovenia |EASTERN EUROPE   ...|   2010347|  MIN|\n",
      "|            Estonia |BALTICS          ...|   1324333|  MIN|\n",
      "|            Bahrain |NEAR EAST        ...|    698585|  MIN|\n",
      "|           Maldives |ASIA (EX. NEAR EA...|    359008|  MIN|\n",
      "|     Western Sahara |NORTHERN AFRICA  ...|    273008|  MIN|\n",
      "|          Gibraltar |WESTERN EUROPE   ...|     27928|  MIN|\n",
      "|             Tuvalu |OCEANIA          ...|     11810|  MIN|\n",
      "|         Montserrat |LATIN AMER. & CAR...|      9439|  MIN|\n",
      "|       Saint Helena |SUB-SAHARAN AFRIC...|      7502|  MIN|\n",
      "|St Pierre & Mique...|NORTHERN AMERICA ...|      7026|  MIN|\n",
      "+--------------------+--------------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wr = Window.partitionBy('Region')\n",
    "cdf.withColumn('minp', f.min('Population').over(wr))\\\n",
    "    .withColumn('maxp', f.max('Population').over(wr)) \\\n",
    "    .where((f.expr('Population==minp or Population==maxp') ) ) \\\n",
    "    .withColumn(\"which\",f.when(f.expr(\"Population==minp\"),'MIN').otherwise('MAX')) \\\n",
    "    .select(\"Country\",\"Region\",\"Population\",\"which\") \\\n",
    "    .sort(\"which\",f.desc(\"Population\")) \\\n",
    "    .show(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
