{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Установка и настройка Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Структура шага\n",
    "\n",
    "* скринкаст cluster_spark (прервать на месте \"сервис пошел стартовать, это займет какое-то время - 01:32)\n",
    "    * по нему слайд \"настройка кластера\"\n",
    "    * чуть деталей в материалах\n",
    "* скринкаст spark_setup \n",
    "    * по нему слайд \"запуск spark приложений\"\n",
    "    * чуть деталей в материалах\n",
    "* скринкаст spark_jupyter\n",
    "    * по нему слайд \"настройки jupyter notebook\"\n",
    "    * детали в материалах\n",
    "    * слайд \"web интерфейс\"\n",
    "    * детали\n",
    "* материалы\n",
    "    * настрока спарка локально\n",
    "    * JDBC\n",
    "    * управление параллелизмом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка кластера\n",
    "\n",
    "* добавляем сервис Spark\n",
    "* (можно остановить Hue, если мало памяти)\n",
    "* spark готов к работе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как увеличить объем используемой памяти\n",
    "\n",
    "После запуска одноименного сервиса, Spark готов к работе. Поскольку на нашем кластере все процессы работают на одном узле, этому узлу может не хватить оперативной памяти. Увеличим объем с 2ГБ до 3ГБ, этого достаточно для того, чтобы работали все наши примеры.\n",
    "\n",
    "* в кластер менеджере заходим в сервис Yarn\n",
    "* вкладка Configuration\n",
    "* находим параметр \"container memory\"\n",
    "\n",
    "![](hadoop_yarn_memory.PNG)\n",
    "\n",
    "* устанавливаем новое значение 3\n",
    "* сохраняем изменения\n",
    "* (через минуту) появляется иконка \"перезагрузить\" \n",
    "\n",
    "![](yarn_restart.PNG)\n",
    "\n",
    "* кликаем ее, дожидаемся перезагрузки Yarn\n",
    "* в WEB интерфейсе менеджера ресурсов должно появиться значение \"3GB\" в верхней строке (\"Memory Total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск Spark приложений\n",
    "\n",
    "* запуск интерактивного shell (scala или python)\n",
    "    * spark-shell (scala)\n",
    "    * pyspark (python)\n",
    "* запуск скомпилированных приложений (JAR)\n",
    "    * spark-submit\n",
    "* мы будем использовать pyspark, а точнее - jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры запуска Spark приложений\n",
    "\n",
    "Для того, чтобы на нашем маленьком кластере работали Spark приложения, необходимо задать следующие параметры\n",
    "\n",
    "* --driver-memory 1G: объем памяти, выделяемый драйверу на узле кластера\n",
    "* --executor-memory 600M: объем памяти, выделяемый экзекьютору\n",
    "\n",
    "Эти параметры нужно задать\n",
    "\n",
    "* в командной строке (при запуске интерактивного spark shell-а)\n",
    "\n",
    "`pyspark --driver-memory 1G --executor-memory 600M`\n",
    "\n",
    "* в качестве значения переменной окружения `PYSPARK_SUBMIT_ARGS` (при работе со spark из jupyter notebook)\n",
    "\n",
    "`os.environ[\"PYSPARK_SUBMIT_ARGS\"] = --driver-memory 1G --executor-memory 600M pyspark-shell`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройки jupyter notebook\n",
    "\n",
    "* стандартная \"шапка\" \n",
    "* создание сессии\n",
    "* интерактивная работа (как обычно в jupyter)\n",
    "* остановка сессии\n",
    "* перезапуск ядра (если что-то нужно поменять в конфигурации)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К материалам курса приложен jupyter notebook с примером, продемонстрированным в скринкасте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web интерфейс\n",
    "\n",
    "* доступен на порту 8088 (в кластер менеджере) или на порту 4040 (локальная установка)\n",
    "* в кластере - через Resource Manager-а (с возможностью принудительной остановки)\n",
    "* можно увидеть процесс выполнения job-а\n",
    "* использование кэша (разберем чуть позже)\n",
    "* информацию о процессах (драйвере и экзекьюторах)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Локальная установка Spark\n",
    "\n",
    "Spark может работать локально (т.е. может быть установлен на рабочем месте, в нашем случае - не в виртуальной машине. Это часто используется для тестирования). В модуле мы будем использовать как кластерный вариант Spark, так и локальный.\n",
    "\n",
    "Как установить и настроить spark для локальной работы:\n",
    "\n",
    "1. Должна быть предустановлена java (установить, если это не так)\n",
    "2. Установить spark (см. инструкции на сайте проекта), он уже может быть установлен (с другими продуктами -  у меня был установлен вместе со scala)\n",
    "3. pip3 install pyspark\n",
    "4. pip3 install ipyparallel\n",
    "\n",
    "Далее в ноутбуке\n",
    "\n",
    "Стандартная шапка:\n",
    "\n",
    "    import os\n",
    "    from pyspark.sql import SparkSession\n",
    "    \n",
    "    os.environ[\"SPARK_HOME\"] = \"<путь куда был установлен pyspark>\"\n",
    "    os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\"\n",
    "    os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"python3\"\n",
    "    os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"pyspark-shell\"\n",
    "\n",
    "Чтобы стартануть сессию делаем\n",
    "\n",
    "    sp = SparkSession.builder.master(\"local\").appName(\"имя_приложения\").getOrCreate()\n",
    "\n",
    "После этого сессию можно видеть здесь:\n",
    "\n",
    "    http://localhost:4040\n",
    "\n",
    "Чтобы остановить сессию делаем\n",
    "\n",
    "    sp.stop()\n",
    "\n",
    "После этого сессия пропадает..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка Spark для работы с JDBC источниками\n",
    "\n",
    "Для работы с реляционными базами данных (например, для чтения данных из них) необходимо установить JDBC драйвер и указать Spark два параметра\n",
    "\n",
    "* --driver-class-path <путь к JDBC драйверу>\n",
    "* --jars <путь к JDBC драйверу>\n",
    "\n",
    "(один и тот же пусть указываем два раза). **ВАЖНО** файл с драйвером должен находиться в одном и том же месте (директории) на всех узлах кластера, на которых будут работать executor-ы, его использующие.\n",
    "\n",
    "Например, для работы с PostgreSQL в нашем кластере нужно будет указать такую комбинацию параметров (см. способы задания параметров выше):\n",
    "\n",
    "`--driver-class-path /usr/share/java/postgresql.jar --jars /usr/share/java/postgresql.jar\n",
    "\n",
    "см. более подробно https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html\n",
    "\n",
    "Мы разберем примеры работы с базами данных в Spark более подробно на следующем шаге этого модуля.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основные параметры параллелизма Spark\n",
    "\n",
    "Spark подразумевает параллельную обработку, как мы уже говорили ранее, dataframe состоит из разделов (`partitions`), каждый из которых хранится и обрабатывается на своем узле кластера. Как правило, количество разделов можно задать в момент создания dataframe. В работе инженера данных наиболее частым способом создания dataframe является его загрузка (из источника - файла или таблицы). Задать количество разделов можно с помощью опции `numPartitions` (более подробно с опциями мы познакомимся на следующем шаге).\n",
    "\n",
    "С другой стороны для параллельной обработки нужны \"обработчики\" (`executors` в терминологии spark). Их количество задается в параметре `--num-executors` при запуске spark приложения. \n",
    "\n",
    "Другими параметрами, связанными с параллельной обработкой, являются\n",
    "\n",
    "* --executor-cores: количество ядер, выделяемых одному executor-у\n",
    "* --executor-memory: объем оперативной памяти, выделяемый одному executor-у\n",
    "\n",
    "**ВАЖНО** некорретное задание этих параметров может привести к одному из следующих исходов (решает логика Spark)\n",
    "\n",
    "* приложение не будет запущено \n",
    "* приложение будет запущено с другими значениями параметров параллелизма (их установит spark)\n",
    "\n",
    "Хорошая статья про partitions: https://medium.com/parrot-prediction/partitioning-in-apache-spark-8134ad840b0"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
