# История формата

ORC: Optimized RC Format (где RC = Record Columnar), собственно базируется на своем предшественнике (RC Format-е) и 
всего-лишь

`the smallest, fastest columnar storage for Hadoop workloads`
  
(это цитата с главной страницы проекта - https://orc.apache.org/. Немного погрузившись - я ей верю...)

Формат уже не юн - создан в 2013 году, сейчас стабильная версия - v1, в работе - v2. 
Достаточно хорошо документирован - все, о чем я здесь пишу, базируется на спецификации 
(https://orc.apache.org/specification/) и проверено питновским кодом (который здесь же).

# Верхнеуровневое описание формата

ORC файл полностью самодостаточен (как и любой другой формат Hadoop - иначе как читать, никаких отдельных метаданных нет...). 
Файл состоит из достаточно больших "страйпов" (stripes) порядка 64МБ каждый и "хвостовичка", содержащего общую для всего файла метаинформацию. Страйп является также самодостаточным (в плане данных) и содержит подмножество строк исходной таблицы. Для чтения данных (подмножества строк) достаточно прочитать хвостовик файла (мета информацию) и страйп(ы), который содержит данные нужных строк.

Формат ориентирован на хранение колонок - в пределах страйпа можно прочитать данные каждой из колонок независимо.

Каждая часть файла (про "части" - ниже) может быть сжата (ZLIB, например), при этом опять же сжатие не должно мешать возможности считать части файла по отдельности.

Файл содержит индексы (на трех уровнях: файл, страйп и блок строк, про блоки - ниже). Что дополнительно ускоряет чтение данных из файла.

Значения колонок хранятся в encoded виде (например, RLE), причем виды кодировки для одной колонки в пределах одного блока строк могут быть разными - все зависит от данных. Кстати, именно этим объясняется тот размер (628 байт), который был приведен выше: данные "легли" так удачно, что RLE кодировка их ну совсем сжала... См. детали ниже.

Ну и в завершение - метаданные хранятся с использованием Protocol Buffers (https://developers.google.com/protocol-buffers/docs/encoding), что тоже прикольно.

# Какая от этого конкретная польза и как ее получить

Формат очень хорошо поддерживается Hadoop-ом, HIVE-у достаточно просто указать, что таблица будет храниться как ORC. Тогда данные таблицы будут храниться в ORC файлах (с ZLIB сжатием по умолчанию).

HIVE имеет утилиту просмотра метаданных ORC файлов, т.е. их можно поизучать (я изучал прямо на питоне по спецификации).

SQOOP пока не поддерживает ORC (говорят, что будет). Поэтому для создания ORC таблиц приходится делать 2 шага

* sqoop таблицу из внешней базы в текстовый файл
* hive создает таблицу с данными из текстового файла

Абсолютные времена последней операции ("перегона" данных из текста в ORC) вполне приемлемы.

Кроме того, можно воспользоваться C++ библиотекой (см. приведенные выше сайт проекта - там есть описание, как собраться С++ библиотеку, я ее собрал - работает) и создавать или читать файлы напрямую из C++.

Сравнение форматов (parquet vs orc) - в процессе. Пока по результатам изучения "ставка" сделана на ORC (хотя в планах изучить parquet также, как и ORC - в байтах...)

# Собственно описание деталей

Вот тут я чуть призадумался - не повторять же здесь спецификацию, в ней все хорошо написано (просто надо внимательно читать).

Наверное вот как лучше сделать: дальнейшее чтение лучше делать в "юпитеровской книжке".

А здесь (ниже) я постараюсь описать то, что "не влезло" непосредственно в книжку (даже интересно - что это будет...).

# Что не влезло в книжку

## Сжатие

`If the ORC file writer selects a generic compression codec (zlib or snappy), every part of the ORC file except for the Postscript is compressed with that codec. However, one of the requirements for ORC is that the reader be able to skip over compressed bytes without decompressing the entire stream. To manage this, ORC writes compressed streams in chunks with headers as in the figure below. To handle uncompressable data, if the compressed data is larger than the original, the original is stored and the isOriginal flag is set. Each header is 3 bytes long with (compressedLength * 2 + isOriginal) stored as a little endian value. For example, the header for a chunk that compressed to 100,000 bytes would be [0x40, 0x0d, 0x03]. The header for 5 bytes that did not compress would be [0x0b, 0x00, 0x00]. Each compression chunk is compressed independently so that as long as a decompressor starts at the top of a header, it can start decompressing without the previous bytes.`

В-общем это надо понимать так:

* если в файле применяется сжатие, то все метаданные (см. структуру ниже) будут сжаты. Про сами данные не понял до конца - сжаты они или нет (в этом примере я сжатие отключил - может быть, попозже обновлю пост, либо напишу отдельно: есть мысль посмотреть, как устроены реальные данные - не из тестового примера, а из базы)
* про каждый блок метаданных известна его длина (и смещение, которое получается обратным счетом - см. книжку)
* тогда нужно отступить 3 байта от начала сжатых данных секции (именно это и хранится в переменной comprOffs - смещение относительно начала секции. Для несжатых файлов это всегда 0)
* считанные "длина секции - 3" байта нужно "декомпрессить" так, как это написано в книжке (zlib deflate)

Не сложно... Но пока я подобрал "все ключи" - ручек в стены полетало...

## Общая структура файла

Все же она недостаточно просто описана в спецификации, ниже приведу свою "версию" описания структуры.

ORC файл состоит из двух логических частей

* повторяющиеся страйпы
* хвостовик (который я упоминал выше)

ORC файл читается

* снизу-вверх (хвостовик)
* сверху вниз (страйпы), точнее - они адресуются по абсолютному смещению в файле и имеют размер (все это хранится в хвостовике)

    *футер страйпа находится в его конце, сначала читается он

Попробую обойтись без рисунка - списком секций (в скобках - длина). Не расписывал все поля - только те, которые позволяют читать файл.

    Повтояющиеся страйпы
        Страйп(ы)
              их размеры известны из хвостовика
              структура страйпа описана в книжке
    Хвостовик
        MetaData, может быть сжать (PostScript.metaDataLength байт)
            содержит информацию о страйпах (сколько строк в каждом, мин макс и сумма каждой колонки), это не позволяет адресоваться по файлу, но позволяет понять, какие страйпы нужно читать
        Footer, может быть сжат (PostScript.footerLength байт)
            содержит количество страйпов (неявно - количество секций)
            про каждый страйп - смещение и длина (длина в разбивке по составным страйпа)
        PostScript, никогда не сжат, гарантированно не может быть длиннее 256 байт (ps байт)
            содержит длину Footer (поле footerLength)
            содержит длину Metadata (поле metadataLength)
        ps: длина PostScript (1 байт)
 
## Все же данные - как же так коротко получается?

В юпитеровской книжке все про данные написано, но кратко все же стоит срезюмировать здесь: как удается так сжать данные?

Данные хранятся в страйпах поколоночно. Каждая колонка - отдельный поток (пока забудем про разбиение внутри страйпа). Внутри потока (=колонки) данные хранятся кодированным образом, но единообразно. Кодировка указывается в стайп футере (см. книжку).

Кодировок достаточно много, давайте остановимся на числовом типе - целом, например:

      Short Repeat - used for short sequences with repeated values
      Direct - used for random sequences with a fixed bit width
      Patched Base - used for random sequences with a variable bit width
      Delta - used for monotonically increasing or decreasing sequences

Внутри одной и той же колонки эти кодировки могут меняться, в-зависимости от данных (колонки). Грубо говоря

* по первым двум байтам можно понять - какая кодировка используется в "фрагменте" (термин мой)
* сколько байт этот фрагмент занимает

Таким образом можно "расшифровать" (раскодировать, наверное, более политкорректно) хранящиеся данные. 

Вернемся к нашему примеру - у нас табличка создавалась таким кусочком кода (оттуда же - из первоисточника, апач).

      struct<x:int,y:int>
      for (i = 0; i < 10000; ++i) {
          x->data[rows] = i;
          y->data[rows] = i * 3;
      }
 
Что имеем в страйпе в потоке, соответствущем первой колонке ("x")

* кодировка Delta (логично - у нас точная дельта)
* первый фрагмент - 4 байта:
      * заголовок 2 байта, он же содержит количество значений, которые должны раскодироваться из этого фрагмента - 511
      * начальное значение (0)
      * дельта (1)
* второй фрагмент - 5 байт:
      * заголовок 2 байта, он же содержит количество значений, которые должны раскодироваться из этого фрагмента - 511
      * начальное значение (512), в "зигзаг" кодироке занимает 2 байта
      * дельта (1)
* и т.д.

Что получается "крупноблочно"

* один 4 байтовый фрагмент
* пять пятибайтовых фрагментов (размер растет за счет зигзаг кодировки начального значения) 
* четырнадцать шестибайтовых фрагментов

Итого - 103 байта (! на 10тыс чисел)

Вторая колонка - аналогично, только там шаг - 3.

# Вместо итого

ORC - весьма продвинутый формат (я еще не смотрел паркет, но, мне кажется, там чуть по-проще. Статья про паркет последует...). 

Если Оракл (и Клик) скрывают то, как они хранят данные внутри, то в случае ORC это достаточно хорошо описано и каждый может разобраться. Что (как минимум) прикольно (см. также ниже).

Что интересно и подлежит обдумыванию:
Сам формат (ORC) предоставляет кучу (пардон за словечко) возможностей по оптимизации

* хранения данных
* доступа к данным

Суметь ими воспользоваться, это 

* задача reader-а
* задача writer-а

Причем читатель и писатель могут быть от разных "авторов"...

Т.е. я, как "писатель" могу "наплевать" на всякие там индексы (как в этом примере, кстати, и сделали с индексами - хотя могу ошибаться...), кодировки и т.п. и тупо записать все 10 тысяч значений "как есть". И это будет корректно (с точки зрения формата). А могу "заморочиться" и получится так, как описано выше.

Точно также "читатель" - может использовать индексы, а может читать все подряд. Может эффективно "раскодировать" вышеизложенное, а может это делать мега неэффективно.

Отсюда

* бенчмарки форматов - бред: сравниваются реализации, не форматы (как таковые)
* если хочется "сжать" - не уверен, что получится сжать лучше, чем ORC + ZLib
* надо понять - можем ли мы (как потребители) что-то "поиметь", зная внутренности того или иного формата.
